
import numpy as np
from os.path import expanduser, normpath
import os

from scipy.spatial import cKDTree


# -------------------------------
def get_error_from_elmer_log(log):
    err = 0.0
    for line in log.splitlines():
        words = line.split()
        if words[0] == "Optimize_m1qn3Parallel:":
            err = float(words[3])

    return err


# --------------------
def bufcount(filename):
    """
    Count how many reads we have to do through one of Elmer's big files
    """
    f = open(filename)
    lines = 0
    buf_size = 1024 * 1024
    read_f = f.read # loop optimization
    buf = read_f(buf_size)
    while buf:
        lines += buf.count('\n')
        buf = read_f(buf_size)
    return lines


# -------------------------------------------
def reconcile_elmer_with_mesh(xt, yt, xe, ye):
    """
    Find a permutation which will map the ordering of the unknowns in the
    Elmer mesh to the original mesh as generated by Triangle
    """
    nn = len(xt)
    p = np.zeros(nn, dtype = int)

    Xe = np.zeros((nn, 2))
    Xe[:,0] = xe
    Xe[:,1] = ye

    Xt = np.zeros((nn, 2))
    Xt[:,0] = xt
    Xt[:,1] = yt

    tree = cKDTree(Xe)

    _, p = tree.query(Xt)

    return p


# --------------------------------------------------------------------------
def get_variable(variable, directory, filename, partitions, verbose = False):
    """
    Read in a variable from output generated by Elmer

    Parameters:
    ==========

    variable:   name of the desired variable output by Elmer
    directory:  path to the files output by Elmer
    filename:   stem of the filename in `directory` where the results are
                    stored, e.g. "Test_Robin_Beta.result" for Fabien's code
    partitions: number of partitions of the underlying mesh

    Returns:
    =======
    data:       a packed numpy array consisting of the x, y, z locations of each
                    node of the mesh along with the values of the desired field
                    at each mesh point
    """

    dstart = np.zeros([2, partitions], dtype = np.int)

    parts_directory = (normpath(directory) + "/partitioning."
                       + str(partitions) + "/")

    # Get the lengths of all the node files
    file_lengths = [bufcount(parts_directory + "part." + str(p) + ".nodes")
                        for p in range(1, partitions + 1)]

    nn = sum(file_lengths)

    if verbose:
        print ("Total number of data points: {0}".format(nn))

    data = np.empty(nn,
                    dtype = [('node', np.int),
                             ('x', np.float64),
                             ('y', np.float64),
                             ('z', np.float64),
                             ('val', np.float64)]
                    )

    # For each partition,
    for p in range(partitions):
        if verbose:
            print ("Reading data for partition {0}".format(p))

        # find the location in the data array where we'll start writing
        start = sum(file_lengths[:p])

        # and open the .nodes file containing the location of each mesh point.
        node_file = open(parts_directory + "part." + str(p + 1) + ".nodes", "r")
        points = node_file.readlines()

        # Fill in all the geometry data stored in this partition's node file.
        for i in range(file_lengths[p]):
            node, _, x, y, z = points[i].split()
            data[start + i] = node, x, y, z, 0.0

        del points
        node_file.close()

        if verbose:
            print ("    Done reading geometry data")

        # Open the result file containing the data we're interested in
        data_file = open(normpath(directory)
                         + "/" + filename + "." + str(p), "r")

        # Find the line number within the result file where our field starts
        while 1:
            line = data_file.readline()
            if not line:
                break
            if variable in line:
                dstart[0, p] = dstart[1, p]
                dstart[1, p] = data_file.tell()

        data_file.seek(0)
        data_file.seek(dstart[0, p])
        line = data_file.readline()
        if line[6:] != "use previous\n":
            for i in range(file_lengths[p]):
                data_file.readline()

        for i in range(file_lengths[p]):
            data['val'][start + i] = float(data_file.readline())

        data_file.close()

        if verbose:
            print "    Done reading ", variable

    data = np.sort(data, order = ['x', 'y', 'z'])
    return data


# --------------------------
def get_layer(data, surface):
    """
    Given one of the big data dumps from `get_variable`, which contains an
    entire 3D field as output by Elmer, return a single 2D layer; either
    the top or bottom surface or the depth-averaged value.
    """

    # Make a function which will get the appropriate value from a vertical
    # column of field values, depending on whether we want the top/bottom
    # surface or depth-averaged value.
    def function_to_get_field(surface):
        if surface == "average":
            def get_field_from_column(column):
                return sum(column['val'])/len(column)
        else:
            if surface == "top":
                argm = np.argmax
            elif surface == "bottom":
                argm = np.argmin
            else:
                raise NameError("Surface needs to be either top, "
                                "bottom or average!")
            def get_field_from_column(column):
                index = argm(column['z'])
                return column[index][4]

        return get_field_from_column

    get_field_from_column = function_to_get_field(surface)

    x, y, q = [], [], []

    # For each unique x- coordinate value,
    for x_val in np.unique(data['x']):
        # select all points that have the same x-value
        data_x = data[ data['x'] == x_val ]

        for y_val in np.unique(data_x['y']):
            # Of those, select all points that have the same x- and y-value
            data_column = data_x[ data_x['y'] == y_val ]

            field_val = get_field_from_column(data_column)

            x.append(data_column[0][1])
            y.append(data_column[0][2])
            q.append(field_val)

    return np.asarray(x), np.asarray(y), np.asarray(q)


# --------------------------------------------------------------------
def get_field(field, directory, partitions, mesh, surface = "average"):
    """
    Get the values of a field from Elmer's output on either the top or
    bottom surface or averaged throughout a vertical column.

    Paramters:
    =========
    field:      name of the field to get, e.g. "beta", "pressure", "velod 1"
    directory:  path to the files output by Elmer
    partitions: the number of partitions of the Elmer mesh
    mesh:       a matplotlib.tri object encapsulating the original Triangle
                mesh used to generated the Elmer mesh
    surface:    either "top", "bottom" or "average"; the layer we want to
                get the field from

    Outputs:
    =======
    q: the desired field, reconciled to the node ordering of `mesh`
    """

    filename = "Test_Robin_Beta.result"

    data = get_variable(field,
                        expanduser(directory),
                        expanduser(filename),
                        partitions)

    x, y, q = get_layer(data, surface)

    permutation = reconcile_elmer_with_mesh(mesh.x, mesh.y, x, y)

    return q[permutation]
